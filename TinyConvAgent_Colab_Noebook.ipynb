{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Masum06/TinyConvAgent/blob/main/TinyConvAgent_Simple_LLM_Agent_framework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wsl---_28-6m"
   },
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r2jTVAqy9BQf",
    "outputId": "83765234-d300-48ae-eff3-293b41001294"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY: ··········\n"
     ]
    }
   ],
   "source": [
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keys import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "4B9SmvFp9J8a"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI, AsyncOpenAI\n",
    "client = OpenAI()\n",
    "async_client = AsyncOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AsyncOpenAI\n",
    "\n",
    "client = AsyncOpenAI()\n",
    "\n",
    "messages = [{'role': 'system', 'content': 'Your name is tiny_agent 🤖.'},\n",
    " {'role': 'system', 'content': 'You perform math.'}]\n",
    "\n",
    "response = await client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=messages,\n",
    "            temperature=0.0,\n",
    "            tool_choice=None\n",
    "        )\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "encoder = tiktoken.encoding_for_model(\"gpt-4o-mini\")\n",
    "len(encoder.encode(\"hello world\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features:\n",
    "\n",
    "- direct chat in notebook\n",
    "- direct chat in CLI\n",
    "- emoji parameter\n",
    "- emotion parameter\n",
    "- emoji classifier\n",
    "- variable for max conv length (0 = inifinity)\n",
    "- React plugin\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "emoji_dict = {'😂': 'HAPPY_high',\n",
    " '🤣': 'HAPPY_high',\n",
    " '🥳': 'HAPPY_high',\n",
    " '🤩': 'HAPPY_high',\n",
    " '🥰': 'HAPPY_high',\n",
    " '😄': 'HAPPY_medium',\n",
    " '😁': 'HAPPY_medium',\n",
    " '😆': 'HAPPY_medium',\n",
    " '😃': 'HAPPY_medium',\n",
    " '🤗': 'HAPPY_medium',\n",
    " '😍': 'HAPPY_medium',\n",
    " '🤠': 'HAPPY_medium',\n",
    " '🤓': 'HAPPY_medium',\n",
    " '🙂': 'HAPPY_low',\n",
    " '😊': 'HAPPY_low',\n",
    " '😌': 'HAPPY_low',\n",
    " '😉': 'HAPPY_low',\n",
    " '👍': 'HAPPY_low',\n",
    " '😇': 'HAPPY_low',\n",
    " '😅': 'HAPPY_low',\n",
    " '🙃': 'HAPPY_low',\n",
    " '😘': 'HAPPY_low',\n",
    " '😭': 'SAD_high',\n",
    " '😿': 'SAD_high',\n",
    " '😞': 'SAD_high',\n",
    " '😫': 'SAD_high',\n",
    " '🤧': 'SAD_high',\n",
    " '😢': 'SAD_medium',\n",
    " '💔': 'SAD_medium',\n",
    " '🥺': 'SAD_medium',\n",
    " '😥': 'SAD_medium',\n",
    " '😓': 'SAD_medium',\n",
    " '😣': 'SAD_medium',\n",
    " '😖': 'SAD_medium',\n",
    " '😔': 'SAD_low',\n",
    " '☹️': 'SAD_low',\n",
    " '😕': 'SAD_low',\n",
    " '😟': 'SAD_low',\n",
    " '🥲': 'SAD_low',\n",
    " '🙁': 'SAD_low',\n",
    " '😲': 'SURPRISED_high',\n",
    " '😵‍💫': 'SURPRISED_high',\n",
    " '😯': 'SURPRISED_high',\n",
    " '😮': 'SURPRISED_high',\n",
    " '🤯': 'SURPRISED_high',\n",
    " '😳': 'SURPRISED_medium',\n",
    " '😦': 'SURPRISED_medium',\n",
    " '😧': 'SURPRISED_medium',\n",
    " '🙀': 'SURPRISED_medium',\n",
    " '🤭': 'SURPRISED_low',\n",
    " '😱': 'AFRAID_high',\n",
    " '😨': 'AFRAID_high',\n",
    " '👻': 'AFRAID_high',\n",
    " '😰': 'AFRAID_medium',\n",
    " '😵': 'AFRAID_low',\n",
    " '🙈': 'AFRAID_low',\n",
    " '😡': 'ANGRY_high',\n",
    " '👿': 'ANGRY_high',\n",
    " '💢': 'ANGRY_high',\n",
    " '🤬': 'ANGRY_high',\n",
    " '☠': 'ANGRY_high',\n",
    " '😠': 'ANGRY_medium',\n",
    " '😾': 'ANGRY_medium',\n",
    " '😤': 'ANGRY_medium',\n",
    " '🙎': 'ANGRY_medium',\n",
    " '🙎‍♂️': 'ANGRY_medium',\n",
    " '🙎‍♀️': 'ANGRY_medium',\n",
    " '😒': 'ANGRY_low',\n",
    " '🙄': 'ANGRY_low',\n",
    " '😑': 'ANGRY_low',\n",
    " '🤮': 'DISGUSTED_high',\n",
    " '🤢': 'DISGUSTED_high',\n",
    " '😝': 'DISGUSTED_high',\n",
    " '😬': 'DISGUSTED_medium',\n",
    " '🥵': 'DISGUSTED_medium'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def separate_emotion(self, response):\n",
    "    emotion = \"NEUTRAL\"\n",
    "    intensity = \"HIGH\"\n",
    "    response = re.sub(\"\\(.*?\\)\",\"()\", response)\n",
    "    response = re.sub(\"\\[.*?\\]\",\"[]\", response)\n",
    "    response = response.replace(\"()\", \"\").replace(\"[]\", \"\")\n",
    "    for char in response:\n",
    "        if char in emoji_dict:\n",
    "            emotion = emoji_dict[char].split(\"_\")[0].upper()\n",
    "            # intensity = emoji_dict[char].split(\"_\")[1].upper()\n",
    "            break\n",
    "    response = emoji.replace_emoji(response, replace='').replace(\"  \", \" \").replace(\" .\", \".\").strip()\n",
    "    return response, emotion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "698cBe76CJNS"
   },
   "source": [
    "# TinyConvAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Persona:\n",
    "    def __init__(self, firstname, lastname=\"\", pronoun=\"\", ethnicity=\"\", age=\"\", bio=\"\"):\n",
    "        self.firstname = firstname\n",
    "        self.lastname = lastname\n",
    "        self.pronoun = pronoun\n",
    "        self.ethnicity = None\n",
    "        self.age = None\n",
    "        self.bio = bio\n",
    "        if not bio:\n",
    "            self.bio = f\"{self.firstname} {self.lastname} (Pronoun: {self.pronoun}) is a virtual human created by researchers at University of Rochester.\"\n",
    "\n",
    "    def set_pronoun(self, pronoun):\n",
    "        self.pronoun = pronoun\n",
    "        \n",
    "    def set_bio(self, bio):\n",
    "        self.bio = bio\n",
    "    \n",
    "    def set_age(self, age):\n",
    "        self.age = age\n",
    "\n",
    "    def set_ethnicity(self, ethnicity):\n",
    "        self.ethnicity = ethnicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def respace(text):\n",
    "    return re.sub(r' {2,}', ' ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "N6_28Cta9DoB"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'await' outside async function (546350344.py, line 50)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[68]\u001b[39m\u001b[32m, line 50\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mawait self.summarize()\u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m 'await' outside async function\n"
     ]
    }
   ],
   "source": [
    "class Conversation:\n",
    "  def __init__(self, user, bot, premise=\"\"):\n",
    "    self.bot = bot\n",
    "    self.user = user\n",
    "    self.premise = \"\"\n",
    "    self.anonymous = False\n",
    "    self.system = []\n",
    "    self.summary = []\n",
    "    self.history = []\n",
    "    self.messages = []\n",
    "    self.temperature = 1\n",
    "    self.max_tokens = 2048\n",
    "    self.summarize_after = 5\n",
    "    self.model = \"gpt-4o-mini\"\n",
    "\n",
    "    self.system.append({\"role\":\"system\", \"content\": \"If the user wants to quit, reply with special token `<|quit|>`.\"})\n",
    "      \n",
    "    if self.bot.firstname:\n",
    "      self.add_system_message(f\"Your first name: {self.bot.firstname}.\")\n",
    "    if self.bot.pronoun:\n",
    "      self.add_system_message(f\"Your pronoun: {self.bot.pronoun}.\")\n",
    "    if self.bot.bio:\n",
    "      self.add_system_message(f\"Your bio: {self.bot.bio}\")\n",
    "    if self.bot.age:\n",
    "      self.add_system_message(f\"Your age: {self.bot.age}\")\n",
    "    if self.user.firstname != \"User\":\n",
    "      self.add_system_message(f\"You are speaking with User: {self.user.firstname} {self.user.lastname}.\")\n",
    "    if self.user.pronoun:\n",
    "      self.add_system_message(f\"User pronoun: {self.user.pronoun}.\")\n",
    "    if self.user.bio:\n",
    "      self.add_system_message(f\"User bio: \"+self.user.bio)\n",
    "\n",
    "  async def get_response(self, messages: list[dict]) -> str:\n",
    "    \"\"\"Return the assistant’s reply text for a list of chat messages.\"\"\"\n",
    "    resp = await async_client.chat.completions.create(\n",
    "        model=self.model,\n",
    "        messages=messages,\n",
    "        temperature=self._temperature,\n",
    "        tool_choice=None,\n",
    "    )\n",
    "    return resp.choices[0].message.content\n",
    "\n",
    "  def add_message(self,message_type, message):\n",
    "    self.messages.append({\"role\": message_type, \"content\":message})\n",
    "    if message_type == \"system\":\n",
    "        self.system.append({\"role\": message_type, \"content\":message})\n",
    "    else:\n",
    "        self.history.append({\"role\": message_type, \"content\":message})\n",
    "    if len(self.messages) >= 2*self.summarize_after:\n",
    "        self.summarize()\n",
    "        \n",
    "  def add_system_message(self, message):\n",
    "    self.add_message(\"system\", message)\n",
    "\n",
    "  def add_bio(self, message):\n",
    "    self.add_message(\"system\", \"You are \" + message)\n",
    "\n",
    "  def add_user_message(self, message):\n",
    "    self.add_message(\"user\", message)\n",
    "\n",
    "  def add_instruction(self, instruction):\n",
    "    self.add_system_message(f\"Follow this instruction: \\n{instruction}\\n\\n\")\n",
    "\n",
    "  def add_example(self, input, output):\n",
    "    self.add_system_message(f\"Example Input: {input}\\nExample Output: {output}\\n\\n\")\n",
    "\n",
    "  def add_data(self, data):\n",
    "    self.add_user_message(f\"Data: {data}\\n\\n\")\n",
    "\n",
    "  def set_temperature(self, temperature):\n",
    "    self.temperature = temperature\n",
    "\n",
    "  def set_max_tokens(self, max_tokens):\n",
    "    self.max_tokens = max_tokens\n",
    "\n",
    "  def set_model(self, model):\n",
    "    self.model = model\n",
    "\n",
    "  def get_transcript(self):\n",
    "    transcript = \"\"\n",
    "    for message in self.history:\n",
    "        if message[\"role\"] == \"user\":\n",
    "            if self.anonymous:\n",
    "                transcript += \"User: \"\n",
    "            else:\n",
    "                transcirpt += self.userfname\n",
    "            transcript += message[\"content\"] + \"\\n\"\n",
    "        elif message[\"role\"] == \"assistant\":\n",
    "            transcript += self.botname + \": \" + message[\"content\"] + \"\\n\"\n",
    "    return transcript\n",
    "\n",
    "\n",
    "  def call(self, prompt=\"\", response_type=\"text\"):\n",
    "    if prompt:\n",
    "      self.add_user_message(prompt)\n",
    "    response = client.chat.completions.create(\n",
    "      model=self.model,\n",
    "      messages=self.system + self.summary + self.messages,\n",
    "      temperature=self.temperature,\n",
    "      max_tokens=self.max_tokens,\n",
    "      top_p=1,\n",
    "      frequency_penalty=0,\n",
    "      presence_penalty=0,\n",
    "      response_format={\n",
    "        \"type\": response_type # \"text\" or \"json_object\"\n",
    "      }\n",
    "    )\n",
    "    reply = response.choices[0].message.content\n",
    "    self.add_message(\"assistant\", reply)\n",
    "    return reply\n",
    "\n",
    "  async def summarize(self):\n",
    "    instruction = [{\"role\":\"system\", \"content\": \"Summarize the dialogue briefly, keeping the main points. Don't say anything else.\"}]\n",
    "    response = await async_client.chat.completions.create(\n",
    "        model=self.model,\n",
    "        messages= instruction + self.messages[:-self.summarize_after],\n",
    "        temperature=self.temperature,\n",
    "        max_tokens=self.max_tokens,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "    )\n",
    "    reply = response.choices[0].message.content\n",
    "    self.messages = self.messages[-self.summarize_after:]\n",
    "    self.summary.append({\"role\": \"assistant\", \"content\": reply})\n",
    "\n",
    "  def respond(self, user_utterance):\n",
    "    response = self.call(user_utterance)\n",
    "    return response\n",
    "\n",
    "  def reset(self):\n",
    "    self.messages = []\n",
    "    self.summary = []\n",
    "    self.history = []\n",
    "\n",
    "  def chat(self,reset=False):\n",
    "    response = \"\"\n",
    "    if reset:\n",
    "        self.reset()\n",
    "    while True:\n",
    "        user_utterance = input()\n",
    "        response = self.respond(user_utterance)\n",
    "        if \"<|quit|>\" in response:\n",
    "            break\n",
    "        print(response)\n",
    "    print(\"Exiting chat\")\n",
    "\n",
    "  def load_json(self,s):\n",
    "    try:\n",
    "        # Attempt to parse the matched JSON\n",
    "        return json.loads(s)\n",
    "    except json.JSONDecodeError:\n",
    "        # Return None if JSON parsing fails\n",
    "        return None\n",
    "\n",
    "  def call_json(self, prompt=\"\"):\n",
    "    reply = self.call(prompt, response_type=\"json_object\")\n",
    "    reply_json = self.load_json(reply)\n",
    "    return reply_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "sU2jlGFU_Lgx"
   },
   "outputs": [],
   "source": [
    "user = Persona(\"Masum\", \"Hasan\", bio=\"I am a PhD student at University of Rochester\")\n",
    "bot = Persona(\"Math Agent\", bio=\"You solve complicated math questions\")\n",
    "conversation = Conversation(user, bot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dG5T6-6X_vLp",
    "outputId": "3505e362-44b6-41a8-efc3-7c5674e1c99d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': 'Your first name: Math Agent.'},\n",
       " {'role': 'system',\n",
       "  'content': 'Your bio: You solve complicated math questions'},\n",
       " {'role': 'system', 'content': 'You are speaking with User: Masum Hasan.'},\n",
       " {'role': 'system',\n",
       "  'content': 'User bio: I am a PhD student at University of Rochester'}]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "LXmeZ0oN_yFk",
    "outputId": "a34a55c9-de6f-4811-dcd0-2d8f32c88f62"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Tell me more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\young\\AppData\\Local\\Temp\\ipykernel_7340\\2024182104.py:50: RuntimeWarning: coroutine 'Conversation.summarize' was never awaited\n",
      "  self.summarize()\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Here are some additional details about Srinivasa Ramanujan and his contributions to mathematics:\n",
      "\n",
      "1. **Notable Contributions**:\n",
      "   - **Ramanujan's Notebook**: Ramanujan compiled a large number of mathematical results in his notebooks, many of which have become famous for their depth and originality. These notebooks contained numerous theorems, formulas, and identities, some of which were previously unknown.\n",
      "   - **Partition Theory**: One of his significant contributions was to partition theory, which deals with the ways of expressing an integer as a sum of positive integers. His work in this area includes formulas for calculating the number of partitions of a number.\n",
      "   - **Modular Forms and q-Series**: Ramanujan worked extensively on modular forms and q-series, leading to results that later played a crucial role in number theory and have connections to areas like string theory in physics.\n",
      "\n",
      "2. **Awards and Recognition**:\n",
      "   - After his death, Ramanujan's legacy continued to grow. Many of his results were verified and developed further, leading to deeper insights in both pure and applied mathematics.\n",
      "   - In honor of his contributions, several concepts and entities were named after him, such as the Ramanujan–Hardy number (1729), which is the smallest number expressible as the sum of two cubes in two different ways.\n",
      "\n",
      "3. **Cultural Depictions**:\n",
      "   - Ramanujan's life has been portrayed in literature and film. One notable work is the biography \"The Man Who Knew Infinity\" by Robert Kanigel, which was also adapted into a film of the same name. The story highlights Ramanujan's journey from India to Cambridge, his relationship with G.H. Hardy, and his remarkable achievements despite the challenges he faced.\n",
      "\n",
      "4. **Mathematical Philosophy**: \n",
      "   - Ramanujan had a unique intuitive approach to mathematics. He often arrived at results that he couldn't rigorously prove but were nonetheless correct. His intuition for numbers and his ability to see patterns were exceptional.\n",
      "\n",
      "If you're interested in any specific aspect of Ramanujan's work or life, feel free to ask!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|quit|>\n",
      "Exiting chat\n"
     ]
    }
   ],
   "source": [
    "conversation.chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SqS0vd0WAA1v",
    "outputId": "c639e91f-4d2d-4df4-f75d-82d9b7a780e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'tell me what is complex number'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'A complex number is a number that has both a real part and an imaginary part. It is usually expressed in the form:\\n\\n\\\\[ z = a + bi \\\\]\\n\\nwhere:\\n- \\\\( z \\\\) is the complex number,\\n- \\\\( a \\\\) is the real part (a real number),\\n- \\\\( b \\\\) is the imaginary part (also a real number), and\\n- \\\\( i \\\\) is the imaginary unit, which is defined as \\\\( i^2 = -1 \\\\).\\n\\nFor example, in the complex number \\\\( 3 + 4i \\\\), the real part is 3 and the imaginary part is 4. Complex numbers can be added, subtracted, multiplied, and divided like real numbers, following specific rules concerning both the real and imaginary components. They are often used in advanced mathematics, engineering, and physics to describe phenomena that cannot be represented by real numbers alone.'},\n",
       " {'role': 'user', 'content': 'quit'},\n",
       " {'role': 'assistant', 'content': '<|quit|>'},\n",
       " {'role': 'user', 'content': 'how are you?'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm here and ready to help you with any math questions you have! How can I assist you today?\"},\n",
       " {'role': 'user', 'content': 'who are you?'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'I am Math Agent, and I specialize in solving complicated math questions. If you have any math-related inquiries, feel free to ask!'},\n",
       " {'role': 'user', 'content': 'tell me about Ramanujan'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"Srinivasa Ramanujan was an Indian mathematician who made significant contributions to mathematical analysis, number theory, infinite series, and continued fractions, despite having little formal training in mathematics. Born on December 22, 1887, in Erode, India, he showed an extraordinary intellectual gift from a young age.\\n\\nSome key highlights about Ramanujan include:\\n\\n1. **Early Life and Education**: He demonstrated advanced mathematical skills while still in school, but his focus on mathematics led him to neglect other subjects, resulting in difficulties in his formal education.\\n\\n2. **Self-Taught Mathematician**: Much of his mathematical knowledge was developed independently, using textbooks and papers he could find. He compiled his findings into several notebooks filled with original theorems.\\n\\n3. **Collaboration with G.H. Hardy**: His breakthrough came when he sent a letter to the prominent British mathematician G.H. Hardy in 1913, showcasing some of his results. Hardy invited him to Cambridge, where they collaborated. Their partnership was incredibly fruitful, leading to many groundbreaking discoveries.\\n\\n4. **Innovative Contributions**: Ramanujan developed several important theories and formulas, including the partition function, which counts the ways of writing a number as a sum of positive integers, and the Ramanujan prime and tau function.\\n\\n5. **Recognition and Legacy**: He was elected a Fellow of the Royal Society in 1918, becoming one of the first Indians to receive this honor. Ramanujan's work has inspired numerous mathematicians and continues to influence areas such as computer science and cryptography.\\n\\n6. **Early Death**: Unfortunately, Ramanujan's life was cut short; he died on April 26, 1920, at the age of just 32. Despite his brief life, his contributions to mathematics remain celebrated and impactful.\\n\\nRamanujan's story is one of genius, perseverance, and the beauty of mathematical discovery, and he is often regarded as one of the greatest mathematicians in history.\"},\n",
       " {'role': 'user', 'content': 'lets close the chat'},\n",
       " {'role': 'assistant', 'content': '<|quit|>'}]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, I can help with math problems! What do you need assistance with?\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TqtIDDnjCA5D"
   },
   "source": [
    "# Extract from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ehUM2XY2Sha"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_json(s):\n",
    "  try:\n",
    "      # Attempt to parse the matched JSON\n",
    "      return json.loads(s)\n",
    "  except json.JSONDecodeError:\n",
    "      # Return None if JSON parsing fails\n",
    "      return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jrBkazrENTHA",
    "outputId": "a8a3c7dc-c750-40fc-d149-9101d4b5340b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 1, 'open-ended-questions': 1}]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_json('[{\"question\": 1, \"open-ended-questions\": 1}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LwClOMVlCrZ5"
   },
   "outputs": [],
   "source": [
    "## Add file upload"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNKq98ehq9ykt+Q/O+lnMu+",
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python (tinyagent)",
   "language": "python",
   "name": "tinyagent"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
